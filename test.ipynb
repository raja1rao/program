{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Item_ID     Item_W  Item_Type    Item_MRP  Outlet_ID  Outlet_Year  \\\n",
      "0      573  21.027499          0  197.352319          3         2004   \n",
      "1      861  21.102371         10  148.250214          2         1987   \n",
      "2      615  20.882263          7  205.465010          2         1999   \n",
      "3      299  21.050435         15  253.417583          3         1996   \n",
      "4      218  21.247876          0  240.871039          2         1988   \n",
      "\n",
      "   Outlet_Size  Outlet_Location_Type  \n",
      "0            2                     1  \n",
      "1            2                     0  \n",
      "2            2                     2  \n",
      "3            2                     0  \n",
      "4            2                     2  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "dataset = pd.read_csv('train.csv')\n",
    "# print(dataset.head())\n",
    "\n",
    "X = dataset.drop(labels=['Sales'], axis = 1)\n",
    "y = dataset['Sales']\n",
    "\n",
    "# print(X.head())\n",
    "label1 = LabelEncoder()\n",
    "X['Item_ID'] = label1.fit_transform(X['Item_ID'])\n",
    "\n",
    "label = LabelEncoder()\n",
    "X['Item_Type'] = label.fit_transform(X['Item_Type'])\n",
    "\n",
    "label2 = LabelEncoder()\n",
    "X['Outlet_Size'] = label2.fit_transform(X['Outlet_Size'])\n",
    "\n",
    "label3 = LabelEncoder()\n",
    "X['Outlet_ID'] = label3.fit_transform(X['Outlet_ID'])\n",
    "\n",
    "label4 = LabelEncoder()\n",
    "X['Outlet_Location_Type'] = label4.fit_transform(X['Outlet_Location_Type'])\n",
    "print(X.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "6151/6151 [==============================] - 4s 578us/step - loss: -348417920.0000 - accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "6151/6151 [==============================] - 4s 582us/step - loss: -3473856768.0000 - accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "6151/6151 [==============================] - 4s 579us/step - loss: -11903952896.0000 - accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "6151/6151 [==============================] - 4s 580us/step - loss: -27847589888.0000 - accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "6151/6151 [==============================] - 4s 583us/step - loss: -53412294656.0000 - accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "6151/6151 [==============================] - 4s 580us/step - loss: -90859855872.0000 - accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "6151/6151 [==============================] - 4s 582us/step - loss: -142186479616.0000 - accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "6151/6151 [==============================] - 4s 579us/step - loss: -209738399744.0000 - accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "6151/6151 [==============================] - 4s 582us/step - loss: -295488815104.0000 - accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "6151/6151 [==============================] - 4s 590us/step - loss: -401563648000.0000 - accuracy: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(X.shape[1], activation='relu', input_dim = X.shape[1]))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam', loss = 'binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "model.fit(X_train, y_train.to_numpy(), batch_size = 10, epochs = 10, verbose = 1)\n",
    "\n",
    "y_pred = (model.predict(X_test) > 0.5).astype(\"int32\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ True]\n",
      " [ True]\n",
      " [ True]\n",
      " ...\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52024    1116.778469\n",
      "73530    1982.124946\n",
      "37040    1817.008632\n",
      "45033    2571.176605\n",
      "37142    2817.981202\n",
      "            ...     \n",
      "67453    1272.034319\n",
      "87429    1949.288329\n",
      "22347    2226.340435\n",
      "54438    1362.164087\n",
      "67911    2364.687475\n",
      "Name: Sales, Length: 26360, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "824/824 [==============================] - 0s 424us/step - loss: -463237939200.0000 - accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[-463237939200.0, 0.0]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of continuous and binary targets",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19400/3706349260.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36mconfusion_matrix\u001b[1;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[0;32m    300\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    301\u001b[0m     \"\"\"\n\u001b[1;32m--> 302\u001b[1;33m     \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    303\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"binary\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"multiclass\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    304\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%s is not supported\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 93\u001b[1;33m         raise ValueError(\n\u001b[0m\u001b[0;32m     94\u001b[0m             \"Classification metrics can't handle a mix of {0} and {1} targets\".format(\n\u001b[0;32m     95\u001b[0m                 \u001b[0mtype_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtype_pred\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Classification metrics can't handle a mix of continuous and binary targets"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "46753d843cc6d8acc63fa8020f8cd656a3a67e30ecad2ef349351746545ac41c"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit (windows store)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
